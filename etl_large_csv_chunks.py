import pandas as pd
from sqlalchemy import create_engine

# é…ç½®
CSV_FILE = './data/large_data.csv'
CHUNK_SIZE = 10000  # æ¯æ¬¡è¯»å–1ä¸‡è¡Œï¼Œå¯æ ¹æ®å†…å­˜è°ƒæ•´

MYSQL_USER = 'root'
MYSQL_PASSWORD = 'root'
MYSQL_HOST = '192.168.254.128'
MYSQL_PORT = '3306'
MYSQL_DB = 'test_Etl'
MYSQL_TABLE = 'processed_large_data'

def transform_data(chunk_df):
    """
    å¯¹æ•°æ®å—è¿›è¡Œè½¬æ¢æˆ–æ¸…æ´—
    """
    # åˆ é™¤ç©ºè¡Œ
    chunk_df = chunk_df.dropna()

    # è½¬æ¢åˆ—åä¸ºå°å†™
    chunk_df.columns = [col.strip().lower() for col in chunk_df.columns]

    # ç¤ºä¾‹ï¼šæ·»åŠ ä¸€åˆ— price_with_tax
    if 'price' in chunk_df.columns:
        chunk_df['price_with_tax'] = chunk_df['price'] * 1.1

    return chunk_df

def load_to_mysql(df_chunk, engine, table_name):
    """
    å°†ä¸€ä¸ªå¤„ç†åçš„æ•°æ®å—å†™å…¥MySQL
    """
    df_chunk.to_sql(
        name=table_name,
        con=engine,
        if_exists='append',  # è¿½åŠ æ¨¡å¼
        index=False,
        method='multi'       # æ‰¹é‡æ’å…¥
    )

def run_etl():
    engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}')

    chunk_count = 0
    for chunk in pd.read_csv(CSV_FILE, chunksize=CHUNK_SIZE):
        chunk_count += 1
        print(f"ğŸ“¦ æ­£åœ¨å¤„ç†ç¬¬ {chunk_count} å—...")

        df_cleaned = transform_data(chunk)
        load_to_mysql(df_cleaned, engine, MYSQL_TABLE)

    print("âœ… æ‰€æœ‰æ•°æ®å—å¤„ç†å®Œæ¯•ï¼")

if __name__ == "__main__":
    run_etl()
